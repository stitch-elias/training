# 生成engine
import tensorrt as trt

logger = trt.Logger(trt.Logger.WARNING)

trt.init_libnvinfer_plugins(None, '')

build = trt.Builder(logger)

net = build.create_network(1<<int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))

parser = trt.OnnxParser(net,logger)
success = parser.parse_from_file("minist_ax.onnx")
for idx in range(parser.num_errors):
    print(parser.get_error(idx))

config = build.create_builder_config()
config.max_workspace_size = 1<<30
build.max_batch_size = 1

profile = build.create_optimization_profile()
profile.set_shape("input_1", (1, 1, 20, 20), (1, 1, 28, 28), (1, 1, 30, 30))
config.add_optimization_profile(profile)

engine = build.build_serialized_network(net,config)

with open("mnist.engine","wb") as f:
    f.write(engine)

# 调用engine
import tensorrt as trt
import pycuda.autoinit
import pycuda.driver as cuda
import numpy as np
import cv2

img = np.asarray(cv2.imread("datas/1.jpg",0).reshape(1,1,28,28),np.float32)

logger = trt.Logger(trt.Logger.WARNING)

with open("mnist.engine","rb") as f, trt.Runtime(logger) as  runtime:
    engine = runtime.deserialize_cuda_engine(f.read())


inputs = []
outputs = []
bindings = []

stream = cuda.Stream()

for count,binding in enumerate(engine):

    dims = engine.get_binding_shape(binding)
    if dims[-1] == -1:
        dims[-2], dims[-1] = 28,28

    size = trt.volume(dims)*engine.max_batch_size
    dtype = trt.nptype(engine.get_binding_dtype(binding))
    host_mem = cuda.pagelocked_empty(size,dtype)
    device_mem = cuda.mem_alloc(host_mem.nbytes)

    bindings.append(int(device_mem))

    if engine.binding_is_input(binding):

        inputs.append([host_mem, device_mem])

    else:

        outputs.append([host_mem, device_mem])

with engine.create_execution_context() as context:

    context.active_optimization_profile = 0  # 增加部分
    origin_inputshape = context.get_binding_shape(0)

    if (origin_inputshape[-1] == -1):
        origin_inputshape[-2], origin_inputshape[-1] = 28,28
        context.set_binding_shape(0, (origin_inputshape))

    inputs[0][0] = img
    [cuda.memcpy_htod_async(inp[1], inp[0], stream) for inp in inputs]

    # cuda.memcpy_htod_async(d_input,h_input,stream)
    #
    context.execute_async(bindings=bindings,stream_handle=stream.handle)
    #
    # cuda.memcpy_dtod_async(h_output,d_output,stream)
    #
    [cuda.memcpy_dtoh_async(out[0], out[1], stream) for out in outputs]

    print(np.array(outputs[0][0]))
    result = np.argmax(np.array(outputs[0][0]))

    stream.synchronize()

    print(result)
    
        #torch-》onnx，trt动态输入调用onnx，
    net = Net()

    net.load_state_dict(torch.load("models/best.ckpt"))

    x = torch.randn((1,1,28,28))

    dynamic_ax={
        "input_1":{2:"image_height",3:"image_width"},
    }

    torch.onnx.export(net, x,
                      "minist_ax.onnx", verbose=False,
                      input_names=['input_1'], output_names=['output_1'],
                      opset_version=11,dynamic_axes=dynamic_ax)
